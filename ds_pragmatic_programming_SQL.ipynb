{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Postgres n SQLITE\n",
    "\n",
    "* KPIs in sql\n",
    "\n",
    "somes refs:\n",
    "\n",
    "    * customer retention: https://blog.statsbot.co/customer-retention-analysis-93af9daee46b\n",
    "    * funnel analysis: https://blog.statsbot.co/sql-queries-for-funnel-analysis-35d5e456371d\n",
    "    \n",
    "        How many subscribe -> how many did audiction -> How many order an report\n",
    "    \n",
    "    * GAMES KPIs\n",
    "    \n",
    "        * https://applift.com/blog/user-retention\n",
    "        * https://medium.com/n3twork/game-analytics-overview-ea8f53ffdff1\n",
    "        * https://www.periscopedata.com/blog/how-to-calculate-cohort-retention-in-sql #A\n",
    "\n",
    "* windows functions\n",
    "* joins\n",
    "* Filters \n",
    "* Transactions #A very important\n",
    "* jaccard and trigrmas (at least postgres support that)\n",
    "\n",
    "* How to insert csv file in sqlite3 in summarize data without worry about memory issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T17:39:21.932370Z",
     "start_time": "2019-04-26T17:39:20.476800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import IPython\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SQLITE\n",
    "\n",
    "* Search how to run sql code in jupyter notebook cells\n",
    "* terminal common command\n",
    "* common SQL queries\n",
    "    * joins\n",
    "    * cross join (cartesian product)\n",
    "* windowing functions (time series) GOOD explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Code to process and add data to sqlite file\n",
    "\n",
    "\n",
    "If the data does not fit in memmory and it is not big data, an alternative is to load the data in sqlite and use sqlite to summarize the data. In the case you need median and qunatiles you can take a large sample that fits in memmory and use python to compute that, so you will have a good estimation of these statistics.\n",
    "\n",
    "refs: https://plot.ly/python/big-data-analytics-with-pandas-and-sqlite/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T17:36:47.986514Z",
     "start_time": "2019-04-26T17:36:47.577531Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-01 07:00:16 W3SVC1574643156 GILMOUR 10.0.1.50 GET /castingworkbook/directors/director_home.asp - 80 - 10.0.1.50 HTTP/1.1 Mozilla/5.0+(Macintosh;+Intel+Mac+OS+X+10_12_6)+AppleWebKit/605.1.15+(KHTML,+like+Gecko)+Version/11.1.2+Safari/605.1.15 http://www.castingworkbook.com/castingworkbook/directors/dmenu2.asp www.castingworkbook.com 200 0 0 16171 1539 375\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 data/logs.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T17:39:24.127399Z",
     "start_time": "2019-04-26T17:39:23.676585Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 21)\n",
      "0 seconds: completed 3 rows\n",
      "(3, 21)\n",
      "0 seconds: completed 6 rows\n",
      "(3, 21)\n",
      "0 seconds: completed 9 rows\n",
      "(2, 21)\n",
      "0 seconds: completed 12 rows\n"
     ]
    }
   ],
   "source": [
    "disk_engine = create_engine('sqlite:///logs.db') \n",
    "\n",
    "chunksize = 3\n",
    "j = 0\n",
    "start = dt.datetime.now()\n",
    "\n",
    "file_name = 'data/logs.log'\n",
    "\n",
    "columns =  [ 'date', 'time', \n",
    "            'site', 'computer_name', 'server_ip', \n",
    "            'request_type', 'uri_stem', 'uri_query', 'port', \n",
    "            'user_name', 'remote_ip', 'cs_version', 'browser', 'referer', 'host',\n",
    "            'http_code', 'sub_status','win32_status',\n",
    "            # https://support.symantec.com/en_US/article.TECH243050.html\n",
    "            # cs-bytes: Number of bytes sent from client to server\n",
    "            # sc-bytes: Number of bytes sent from server to client\n",
    "            'sc_bytes','cs_bytes',\n",
    "            'loading_time' ]\n",
    "\n",
    "columns_to_drop = ['computer_name', 'uri_query', 'user_name', 'cs_version', \n",
    "                   'host', \n",
    "                   'sub_status','win32_status' ]\n",
    "\n",
    "for df in pd.read_csv(file_name, sep=' ',index_col=False, header=None, chunksize=chunksize, iterator=True, encoding='utf-8'):\n",
    "    \n",
    "    print(df.shape)\n",
    "    df.columns = columns\n",
    "     \n",
    "    # drop columns\n",
    "    for c in columns_to_drop:\n",
    "        df = df.drop(c, axis=1)\n",
    "  \n",
    "    # Do MORE processing in the columns\n",
    "\n",
    "    # Insert data\n",
    "    df.to_sql('log', disk_engine, if_exists='append')\n",
    "    \n",
    "    j+=1\n",
    "    print('{} seconds: completed {} rows'.format((dt.datetime.now() - start).seconds, j*chunksize))\n",
    "\n",
    "    #assert j <= 3, \"Break time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T17:40:35.843425Z",
     "start_time": "2019-04-26T17:40:35.725564Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0|2018-10-01|07:00:16|W3SVC1574643156|10.0.1.50|GET|/castingworkbook/directors/director_home.asp|80|10.0.1.50|Mozilla/5.0+(Macintosh;+Intel+Mac+OS+X+10_12_6)+AppleWebKit/605.1.15+(KHTML,+like+Gecko)+Version/11.1.2+Safari/605.1.15|http://www.castingworkbook.com/castingworkbook/directors/dmenu2.asp|200|16171|1539|375\r\n",
      "1|2018-10-01|07:00:16|W3SVC1574643156|10.0.1.50|GET|/castingworkbook/newFeatures.asp|80|10.0.1.50|Mozilla/5.0+(Macintosh;+Intel+Mac+OS+X+10_12_6)+AppleWebKit/605.1.15+(KHTML,+like+Gecko)+Version/11.1.2+Safari/605.1.15|http://www.castingworkbook.com/castingworkbook/directors/director_home.asp|200|189|1545|15\r\n",
      "2|2018-10-01|07:00:18|W3SVC1574643156|10.0.1.50|GET|/castingworkbook/agents/shows.asp|80|10.0.1.50|Mozilla/5.0+(Macintosh;+Intel+Mac+OS+X+10_13_6)+AppleWebKit/605.1.15+(KHTML,+like+Gecko)+Version/12.0+Safari/605.1.15|http://www.castingworkbook.com/castingworkbook/agents/shows.asp?type=invitation|200|88306|1095|312\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!sqlite3 logs.db 'SELECT * FROM  log LIMIT 3;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postgresq\n",
    "\n",
    "\n",
    "Ref: https://gitlab.com/leandroohf/postgres_train (my repo in GitLab)\n",
    "\n",
    "* Search how to run sql code in jupyter notebook cells\n",
    "* terminal common command\n",
    "* common SQL queries\n",
    "    * joins\n",
    "    * cross join (cartesian product)\n",
    "    * find the name of the special join that allows you in  a subquery use keyword defined outside\n",
    "* KPIS (since is more likelly to use here and postgresql is more popular)\n",
    "* windowing functions (time series) GOOD explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start postgresql server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.digitalocean.com/community/tutorials/how-to-install-and-use-postgresql-on-ubuntu-18-04\n",
    "* https://www.digitalocean.com/community/tutorials/how-to-install-postgresql-on-ubuntu-20-04-quickstart\n",
    "\n",
    "```sh\n",
    "\n",
    "# Install\n",
    "sudo apt update\n",
    "sudo apt install postgresql postgresql-contrib\n",
    "\n",
    "\n",
    "# double check installation\n",
    "sudo -u postgres psql -c \"SELECT version();\"\n",
    "\n",
    "\n",
    "# switch to posthgresl user\n",
    "sudo -i -u postgres\n",
    "\n",
    "# or \n",
    "sudo -u postgres psql\n",
    "\n",
    "## Inside psql prompt\n",
    "# create a new db\n",
    "CREATE DATABASE time_series;\n",
    "\n",
    "\\list\n",
    "\n",
    "## connect to time_series db using client like dbeaver\n",
    "\n",
    "# change default password for user postgres in psql shell\n",
    "# https://enterprise.arcgis.com/en/server/10.3/cloud/amazon/change-default-database-passwords-on-linux.htm\n",
    " \\password postgres\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to a db\n",
    "\n",
    "ref:\n",
    "* https://www.cybertec-postgresql.com/en/postgresql-detecting-periods-of-activity-in-a-timeseries/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* From csv file\n",
    "\n",
    "\n",
    "```sh\n",
    "psql -U postgres -d bike_data -h localhost -c \"\\COPY bikes FROM bikeshare.csv CSV\"\n",
    "\n",
    "```\n",
    "\n",
    "* From SQL \n",
    "\n",
    "```sql\n",
    "\n",
    "-- https://www.cybertec-postgresql.com/en/postgresql-detecting-periods-of-activity-in-a-timeseries/\n",
    "-- XXX: NOT WORKING. NEED TO DISCOVER WHY?\n",
    "CREATE TABLE t_series (t date, data int);\n",
    " \n",
    "COPY t_series FROM stdin DELIMITER ';';\n",
    "2018-03-01;12\n",
    "2018-03-02;43\n",
    "2018-03-03;9\n",
    "2018-03-04;13\n",
    "2018-03-09;23\n",
    "2018-03-10;26\n",
    "2018-03-11;28\n",
    "2018-03-14;21\n",
    "2018-03-15;15\n",
    "\\.\n",
    "\n",
    "```\n",
    "\n",
    "* From dataframe\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "df.to_sql()\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read with pandas for one time analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "user = 'x'\n",
    "pwd = 'x'\n",
    "host = 'xxxx'\n",
    "db = 'db'\n",
    "\n",
    "engine = create_engine(f'postgresql://{user}:{pwd}@d{host}:5432/{db}')\n",
    "\n",
    "query = \"\"\"\n",
    "select *\n",
    "from table_eith_data t \n",
    "\"\"\"\n",
    "\n",
    "# XXX: BEcareful. This line wil replace any existing table\n",
    "demo_df = pd.read_sql_query(query, engine)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from db by chunks (For large data sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Common operation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Create Table  \n",
    "\n",
    "```sql\n",
    "\n",
    "-- logins table  \n",
    "CREATE TABLE IF NOT EXISTS users.logins (\n",
    "ID id SERIAL     --- auto increment. sqlite the keywords is \"autoincrement\"\n",
    "\"date\" DATE UNIQUE,\n",
    "user_type INT,\n",
    "n_logins INT,\n",
    "UNIQUE (\"date\")  -- constraint: date should be unique\n",
    "PRIMARY KEY ID\n",
    ");\n",
    "\n",
    "```\n",
    "\n",
    "* Clear data in table \n",
    "\n",
    "\n",
    "```sql\n",
    "\n",
    "DELETE FROM medias;\n",
    "\n",
    "\n",
    "-- BETTER\n",
    "DELETE FROM medias \n",
    "WHERE media_id = '1234';\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "* Delete Table\n",
    "\n",
    "```sql\n",
    "\n",
    "DROP TABLE medias.growth;\n",
    "\n",
    "DROP DATABASE \"voicematchseedtest\";\n",
    "```\n",
    "\n",
    "\n",
    "* Contraints\n",
    "\n",
    "https://pganalyze.com/docs/log-insights/app-errors/U125  \n",
    "https://www.postgresqltutorial.com/postgresql-unique-constraint/  \n",
    "https://www.postgresql.org/docs/9.4/ddl-constraints.html  \n",
    "\n",
    "So you can use things like ON CONFLICTS DO SOMETHING\n",
    "\n",
    "\n",
    "```sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS users.logins (\n",
    "\"date\" DATE,\n",
    "user_type INT,\n",
    "n_logins INT,\n",
    "UNIQUE (\"date\", user_type)  -- constraint unique pair \n",
    ");\n",
    "\n",
    "\n",
    "-- You need to get the name of the constraint on dbeaver client\n",
    "INSERT INTO users.logins (\"date\", user_type, n_logins) \n",
    "VALUES ('2020-08-03', 8, 2)\n",
    "ON CONFLICT ON CONSTRAINT logins_date_user_type_key   -- constraint name. See dbeaver\n",
    "DO nothing;\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### CTE\n",
    "\n",
    "Helps a lot with analytcs\n",
    "1. It is easy to debug and understand\n",
    "1. We can build the cte tables by parts and check the results\n",
    "1. The query is more readbale and easy to add commentaries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Example with muliple CTEs\n",
    "\n",
    "```sql\n",
    "WITH Active_accounts_cte (gender, cityid, city, yob, clientid, serviceid) -- complex table with all active account candidates\n",
    "        AS\n",
    "        (\n",
    "            SELECT c.gender, c.residence, lc.description,\n",
    "                CONVERT(varchar(4),c.birthday , 120) AS yob,\n",
    "                clientid,\n",
    "                servicerid AS serviceid\n",
    "            FROM [clients].[dbo].[tblclients] c\n",
    "            LEFT JOIN [casting]..lstCities lc ON lc.cityID = c.residence\n",
    "            WHERE c.[status] > 0  -- complex criteria \n",
    "                AND servicerid <> 94 -- exclude phanthom service\n",
    "        ),\n",
    "        Roster_cte (clientid)  -- complex table with all actors that is a member of a roster\n",
    "        AS\n",
    "        (\n",
    "            SELECT DISTINCT clientrid AS clientid\n",
    "            FROM [clients]..tblrosters AS r\n",
    "            WHERE r.status > 0  -- complex criteria \n",
    "                AND r.agentrid <> 10\n",
    "        )\n",
    "        SELECT  CONVERT(varchar(10),GETDATE(), 120)  AS 'date',\n",
    "            a.gender, a.cityid , a.city, a.yob,\n",
    "            a.clientid as clientid, a.serviceid\n",
    "        FROM Active_accounts_cte a\n",
    "        -- Count only actors that can be used. Is a member of at least one roster\n",
    "        LEFT JOIN Roster_cte r ON a.clientid = r.clientid\n",
    "        WHERE a.clientid IN (SELECT clientid FROM  Roster_cte)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data wrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Date and type cast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```sql\n",
    "select to_char(o.process_date, 'YYYY-MM') as process_date ,\n",
    "from users.orders o \n",
    "\n",
    "select CAST (SUM(Seconds) AS FLOAT)\n",
    "from time_table\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Table columns and rows manipulations\n",
    "\n",
    "refs:\n",
    "* https://modern-sql.com/excel/sumif-in-sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Table in the initial format\n",
    "\n",
    "```sql\n",
    "select to_char(o.process_date, 'YYYY-MM') as process_date , o.service_category,\n",
    "\t\tSUM(o.qtd) as qtd\n",
    "from users.orders o \n",
    "group by to_char(o.process_date, 'YYYY-MM'), o.service_category\n",
    "order by to_char(o.process_date, 'YYYY-MM') desc \n",
    "limit 15;\n",
    "```\n",
    "\n",
    "process_date|service_category|qtd |\n",
    "------------|----------------|----|\n",
    "2020-11     |monthly         | 281|\n",
    "2020-11     |one_time        |   1|\n",
    "2020-11     |credit          |   4|\n",
    "2020-11     |yearly          | 409|\n",
    "2020-11     |other           |   2|\n",
    "2020-10     |one_time        |   1|\n",
    "2020-10     |yearly          |1726|\n",
    "2020-10     |monthly         | 427|\n",
    "2020-10     |credit          |   3|\n",
    "2020-09     |yearly          |1391|\n",
    "2020-09     |monthly         | 380|\n",
    "2020-09     |other           |   2|\n",
    "\n",
    "\n",
    "* Convert to \n",
    "\n",
    "```sql\n",
    "select to_char(o.process_date, 'YYYY-MM') as process_date ,\n",
    "\t\tSUM(CASE WHEN o.service_category = 'yearly' THEN o.qtd  end) as yearly,\n",
    "\t\tSUM(CASE WHEN o.service_category = 'monthly' THEN o.qtd  end) as monthly\n",
    "from users.orders o \n",
    "group by to_char(o.process_date, 'YYYY-MM')\n",
    "order by to_char(o.process_date, 'YYYY-MM') desc \n",
    "limit 15;\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "process_date|yearly|monthly|\n",
    "------------|------|-------|\n",
    "2020-11     |   409|    281|\n",
    "2020-10     |  1726|    427|\n",
    "2020-09     |  1391|    380|\n",
    "2020-08     |  4559|    260|\n",
    "2020-07     |   395|    156|\n",
    "2020-06     |   305|    158|\n",
    "2020-05     |   154|     75|\n",
    "2020-04     |    91|     52|\n",
    "2020-03     |  1427|    134|\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```sql\n",
    "select \"date\",\n",
    "\tcase\n",
    "\t\twhen user_type = 8 then 'Actor'\n",
    "\t\twhen user_type = 2 then 'Director'\n",
    "\t\twhen user_type = 3 then 'Agent'\n",
    "\t\telse ''\n",
    "\tend as user_type,\n",
    "from users \n",
    "limit 11;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Time Series Analysis time series db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Window function: lag and first_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```sql\n",
    "\n",
    "-- Create \n",
    "CREATE TABLE timestamps (\n",
    "  ts timestamp,\n",
    "  n_audios INT\n",
    ");\n",
    "\n",
    "INSERT INTO timestamps VALUES\n",
    "  ('2015-05-01 12:15:23.0', 1),\n",
    "  ('2015-05-01 12:15:24.0',2),\n",
    "  ('2015-05-01 12:15:27.0',3),\n",
    "  ('2015-05-01 12:15:31.0',4),\n",
    "  ('2015-05-01 12:15:40.0',5),\n",
    "  ('2015-05-01 12:15:55.0',7),\n",
    "  ('2015-05-01 12:16:01.0',9),\n",
    "  ('2015-05-01 12:16:03.0',13),\n",
    "  ('2015-05-01 12:16:04.0',17),\n",
    "  ('2015-05-01 12:16:04.0',10);\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```sql\n",
    "SELECT\n",
    "  ts, \n",
    "  ts - lag(ts, 1) OVER (ORDER BY ts) delta,\n",
    "  n_audios,\n",
    "  n_audios - lag(n_audios , 1) OVER (ORDER BY ts) d_audio\n",
    "FROM timestamps\n",
    "ORDER BY ts;\n",
    "\n",
    "SELECT\n",
    "  ts, \n",
    "  ts - lag(ts, 1) OVER w delta,\n",
    "  ts - first_value(ts) OVER w total,\n",
    "  n_audios,\n",
    "  n_audios - lag(n_audios , 1) OVER w d_audio\n",
    "FROM timestamps\n",
    "WINDOW w AS (ORDER BY ts)\n",
    "ORDER BY ts;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Window function: move average\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "refs:\n",
    "* https://www.compose.com/articles/metrics-maven-calculating-a-moving-average-in-postgresql/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize data\n",
    "\n",
    "5 nuymbers: min, mean, median, max and std\n",
    "\n",
    "refs:\n",
    "* https://leafo.net/guides/postgresql-calculating-percentile.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Take random sample of a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```sql\n",
    "with rd_cte \n",
    "as\n",
    "(\n",
    "    select t.* , random() as rd\n",
    "    from timestamps t\n",
    ")\n",
    "select *\n",
    "from rd_cte \n",
    "where rd > 0.5;\n",
    "\n",
    "\n",
    "select t.* \n",
    "from timestamps t\n",
    "where random() > 0.5;\n",
    "\n",
    "-- Create an user defined function\n",
    "CREATE OR REPLACE FUNCTION random_between(low INT ,high INT) \n",
    "   RETURNS INT AS\n",
    "$$\n",
    "BEGIN\n",
    "   RETURN floor(random()* (high-low + 1) + low);\n",
    "END;\n",
    "$$ language 'plpgsql' STRICT;\n",
    "\n",
    "select t.* , random_between(1,100) as rd\n",
    "from timestamps t;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Materialzed View \n",
    "\n",
    "refs:\n",
    "* https://www.compose.com/articles/its-a-view-its-a-table-no-its-a-materialized-view/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "410.66px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
