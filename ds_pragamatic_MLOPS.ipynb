{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOPS\n",
    "\n",
    "Snippet codes for deploy ML applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Search more about good practices\n",
    "\n",
    "1. You need to change enviroment just change configuration files or enviroment variables and NOT code. The code should be the same running on developement, staging or production\n",
    "\n",
    "1. Use enviroment variable\n",
    "    * credentials. You can add this envriroment variable in the .env file on your home\n",
    "    * databases or other resources addreess and etc\n",
    "\n",
    "1. Share nothing archicteture (for easy scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quick documenattion\n",
    "\n",
    "\n",
    "```sh\n",
    "tldr tar\n",
    "\n",
    "```\n",
    "\n",
    "* emacs package howdoyou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "\n",
    "# get ip of the machine \n",
    "ip addr show  # new interface\n",
    "ifconfig  # old one\n",
    "\n",
    "\n",
    "# ssh using key\n",
    "#ssh -i \"path_to_server.pem\" user@hostname_or_ip\n",
    "ssh -i \"server.pem\" ubuntu@X.Y.W.Z\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS \n",
    "\n",
    "ref: udacity course material it is a goodreference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "* List of main services what does it do. Waht is good for. Comomn mistakes and do not use it?\n",
    "\n",
    "    1. S3\n",
    "    1. RDS \n",
    "    1. Dynamodb\n",
    "    1. Redshift  <=== for caching. Most recent date is caching, then migrate to postgresql db old data\n",
    "    1. Kafka <== \n",
    "    1. EC2\n",
    "    1. ECR\n",
    "    1. EKS  <== \n",
    "    1. EMR  <===\n",
    "    1. ROUTE53 \n",
    "    1. VPC\n",
    "\n",
    "* Main boring tasks like:\n",
    "\n",
    "    * set IAM\n",
    "    * set group permission\n",
    "    * open port \n",
    "\n",
    "* Main terms\n",
    "\n",
    "    * region\n",
    "    * AZ\n",
    "    * VPC\n",
    "    * Install and set AWS CLI\n",
    "    \n",
    "* Analytics and ML\n",
    "\n",
    "    * Athena\n",
    "    * sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "aws --version\n",
    "\n",
    "# tets credentials and get you identity\n",
    "aws sts get-caller-identity\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3\n",
    "refs:\n",
    "* https://docs.aws.amazon.com/cli/latest/reference/s3/rm.html\n",
    "* https://stackoverflow.com/questions/51375531/aws-cli-s3-bucket-remove-object-with-date-condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview commands \n",
    "\n",
    "```sh\n",
    "aws s3 any_command --dryrun\n",
    "\n",
    "```\n",
    "\n",
    "Clean S3 bucket fastest way\n",
    "\n",
    "```sh\n",
    "aws s3 rm s3://bucket-dev --recursive\n",
    "\n",
    "# exclude pattern\n",
    "aws s3 rm s3://mybucket/ --recursive --exclude \"*.jpg\"\n",
    "\n",
    "```\n",
    "\n",
    "Useful commands\n",
    "```sh\n",
    "# list all buckets name accross all regions\n",
    "aws s3api list-buckets --query \"Buckets[].Name\"\n",
    "\n",
    "# list files in the buckets\n",
    "aws s3 ls s3://bucket-dev\n",
    "\n",
    "# delete key\n",
    "aws s3 rm s3://bucket-dev/test2.txt\n",
    "\n",
    "# delete all txt\n",
    "aws s3 rm s3://bucket-dev/test-folder/ --include \"*.txt\"\n",
    "\n",
    "# count number of files\n",
    "aws s3 ls --recursive s3://bucket-dev/ | wc -l\n",
    "```\n",
    "\n",
    "**delete multiple files based on pattern**\n",
    "<p style=\"color:red\"># BECAREFUL: THIS COMMAND DO NOT ASK TO DELETE BEFORE DELETE</p>\n",
    "\n",
    "```sh\n",
    "\n",
    "# 1) filter the files based on pattern match using grep\n",
    "aws s3 ls s3://bucket-dev/ | awk '{print $4}' | grep -E -i 00a5b462ef48280440ecc6af98133d77_leandro_test2\n",
    "aws s3 ls s3://bucket-dev/ | awk '{print $4}' | grep -E -i \".*ts\" | wc -l\n",
    "\n",
    "# 2) Pass the output to xargs\n",
    "aws s3 ls s3://bucket-dev/ | awk '{print $4}' | grep -E -i 00a5b462ef48280440ecc6af98133d77_leandro_test2 | xargs -I% echo %_TEXTTTT\n",
    "\n",
    "\n",
    "# 3) Use xrags to run aws s3 rm key\n",
    "aws s3 ls s3://bucket-dev/ | awk '{print $4}' | grep -E -i 00a5b462ef48280440ecc6af98133d77_leandro_test2 | xargs -I% bash -c 'aws s3 rm s3://bucket-dev/%'\n",
    "\n",
    "```\n",
    "\n",
    "**delete mutliple files based on date condition**\n",
    "<p style=\"color:red\"># BECAREFUL: THIS COMMAND DO NOT ASK TO DELETE BEFORE DELETE</p>\n",
    "\n",
    "```sh\n",
    "\n",
    "# 1) count the number of files first\n",
    "aws s3 ls --recursive s3://bucket-dev/ | awk '$1 > \"2021-01-20\" && $1 < \"2021-02-01\" {print $4}'|  sort -n | wc -l\n",
    "\n",
    "# 2) Use xargs to delete. xrags explanation: -n1 mean only one arg per line -t means verbose\n",
    "aws s3 ls --recursive s3://bucket-dev/ | awk '$1 > \"2021-01-20\" && $1 < \"2021-02-01\" {print $4}'|  sort -n | xargs -I% bash -c 'aws s3 rm s3://bucket-dev/%'\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mount S3 in EC2 instance\n",
    "https://linuxbeast.com/tutorials/aws/install-s3fs-and-mount-s3-bucket-on-ubuntu-18-04/\n",
    "\n",
    "\n",
    "It works even in different **AZ** Availability zones <<= cool, CDNs might use this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside EC2 instance:\n",
    "```shell\n",
    "sudo apt-get update\n",
    "\n",
    "sudo apt install s3fs awscli -y\n",
    "\n",
    "which s3fs\n",
    "\n",
    "# echo ACCESS_KEY_ID:SECRET_ACCESS_KEY > /home/ubuntu/.s3fs-creds\n",
    "echo AXXQ:iXXXXXXXS > /home/ubuntu/.s3fs-creds\n",
    "\n",
    "chmod 600 /home/ubuntu/.s3fs-creds\n",
    "\n",
    "ls -la\n",
    "\n",
    "mkdir /home/ubuntu/s3_uploads\n",
    "\n",
    "# mount command. Only root can access this way\n",
    "sudo s3fs cwb-test-mount-multiple-ec2-instance /home/ubuntu/s3_uploads -o passwd_file=/home/ubuntu/.s3fs-creds,nonempty\n",
    "\n",
    "\n",
    "# see test.txt file in both ec2 instances\n",
    "sudo la s3_uploads\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python (boto3) interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Clean bucket\n",
    "\n",
    "```python\n",
    "import boto3  \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('my-bucket')\n",
    "\n",
    "# suggested  \n",
    "bucket.objects.all().delete()\n",
    "```\n",
    "\n",
    "* List objects filter by prefix\n",
    "\n",
    "\n",
    "```python\n",
    "import boto3  \n",
    "import botocore\n",
    "\n",
    "print(boto3.__version__)\n",
    "print(botocore.__version__)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('my-bucket')\n",
    "\n",
    "_prefix = 'd3541cc0a24e06300308fa9f994405db_leandro_snap_3__uid_s_10005__uid_e_video_'\n",
    "resp = bucket.meta.client.list_objects_v2( Bucket='my-bucket',\n",
    "                                       Prefix =_prefix,\n",
    "                                       MaxKeys=5)\n",
    "\n",
    "for idx, obj in enumerate(resp['Contents']):\n",
    "\n",
    "    key = obj['Key']\n",
    "    print(f\"{idx}: {key}\")\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "* Generate URI for download\n",
    "\n",
    "```python\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('cwb-agoraio-dev')\n",
    "\n",
    "\n",
    "response = s3_client.generate_presigned_url('get_object',\n",
    "                                            Params={'Bucket': bucket_name, 'Key': key},\n",
    "                                            ExpiresIn=22000)\n",
    "\n",
    "```\n",
    "\n",
    "* Save file to bucket\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.18\n",
      "1.19.18\n",
      "0: d3541cc0a24e06300308fa9f994405db_leandro_snap_3__uid_s_10005__uid_e_video_20210222224056763.jpg; https://cwb-agoraio-dev.s3.amazonaws.com/d3541cc0a24e06300308fa9f994405db_leandro_snap_3__uid_s_10005__uid_e_video_20210222224056763.jpg?AWSAccessKeyId=AKIAJVWT7CW755R5UG3Q&Signature=oDUgELE829m%2BtGYg1LlilxB0TpA%3D&Expires=1614081368\n",
      "1: d3541cc0a24e06300308fa9f994405db_leandro_snap_3__uid_s_10005__uid_e_video_20210222224101801.jpg; https://cwb-agoraio-dev.s3.amazonaws.com/d3541cc0a24e06300308fa9f994405db_leandro_snap_3__uid_s_10005__uid_e_video_20210222224101801.jpg?AWSAccessKeyId=AKIAJVWT7CW755R5UG3Q&Signature=fNv19bJzT430OLJo9HxCfntirJA%3D&Expires=1614081368\n"
     ]
    }
   ],
   "source": [
    "import boto3  \n",
    "import botocore\n",
    "\n",
    "print(boto3.__version__)\n",
    "print(botocore.__version__)\n",
    "\n",
    "bucket_name = 'cwb-agoraio-dev'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "_prefix = 'd3541cc0a24e06300308fa9f994405db_leandro_snap_3__uid_s_10005__uid_e_video_'\n",
    "resp = bucket.meta.client.list_objects_v2( Bucket=bucket_name,\n",
    "                                       Prefix =_prefix,\n",
    "                                       MaxKeys=5)\n",
    "\n",
    "for idx, obj in enumerate(resp['Contents']):\n",
    "\n",
    "    key = obj['Key']\n",
    "\n",
    "    uri = s3_client.generate_presigned_url('get_object',\n",
    "                                            Params={'Bucket': bucket_name, 'Key': key},\n",
    "                                            ExpiresIn=22000)\n",
    "    \n",
    "    print(f\"{idx}: {key}; {uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20210222224101801'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, datetime\n",
    "\n",
    "key = 'd3541cc0a24e06300308fa9f994405db_leandro_snap_3__uid_s_10005__uid_e_video_20210222224101801.jpg'\n",
    "\n",
    "match = re.search('_(\\d{17})\\.', key)\n",
    "\n",
    "utc =  match.group()\n",
    "\n",
    "# utc =utc.replace('_','')\n",
    "\n",
    "# utc = utc.replace('.','')\n",
    "\n",
    "utc = utc[1:-1]\n",
    "\n",
    "utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "\n",
    "# Select output type\n",
    "# --output table, json or text [default]\n",
    "\n",
    "# get instances running for a region\n",
    "#aws ec2 describe-instances --region $region\n",
    "aws ec2 describe-instances --region us-west-2 --output text\n",
    "\n",
    "# get ec2 instance info\n",
    "aws ec2 describe-instances --instance-id i-0bxxxcc --output table\n",
    "\n",
    "# list all ec2 intasnces running\n",
    "for region in `aws ec2 describe-regions --region us-east-1 --output text | cut -f4`\n",
    "do\n",
    "     echo -e \"\\nListing Instances in region:'$region'...\"\n",
    "     aws ec2 describe-instances --region $region\n",
    "done\n",
    "\n",
    "# list all EC2 instance with Name  <=== #A This putput is very convenient\n",
    "aws ec2 describe-instances \\\n",
    "              --filters Name=tag-key,Values=Name \\\n",
    "              --query 'Reservations[*].Instances[*].{Instance:InstanceId,AZ:Placement.AvailabilityZone,Name:Tags[?Key==`Name`]|[0].Value}' \\\n",
    "              --output table\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main terms\n",
    "\n",
    "Maybe add some FAQ or doubts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### docker\n",
    "\n",
    "What does he do?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "# list images\n",
    "docker images\n",
    "\n",
    "# build image: New version no command putput is printed\n",
    "docker docker build .\n",
    "\n",
    "\n",
    "# for see command outpus use:\n",
    "export DOCKER_BUILDKIT=0\n",
    "docker docker build .\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### docker-compose \n",
    "\n",
    "\n",
    "What does he do?\n",
    "* automitize build docker images, start , mount volumes and create networks based on yaml files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "docker-compose -f docker-compose-dev.yml build\n",
    "docker-compose -f docker-compose-dev.yml up\n",
    "docker-compose -f docker-compose-dev.yml down\n",
    "```\n",
    "\n",
    "\n",
    "Acess docker logs from local machine\n",
    "\n",
    "```shell\n",
    "docker-compose logs --tail=\"all\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### docker-machine \n",
    "\n",
    "What does he do? The tool to be able to create a remote virtual machine (VM) easily and manage those containers.\n",
    "\n",
    "* automitize the process of \n",
    "    1. create machine instance in locl and cloud servise\n",
    "    1. ssh to this machines \n",
    "    1. manage multiples machines\n",
    "    \n",
    "Crons:\n",
    "* It is centralized. It is not easy to move the docker-machine nad its configuration with all machines to a different deployment service. kubectk is easy for that\n",
    "\n",
    "* docker and docker-machine has a lot of bug due to incompatible versions between them. So always keep than updated and in sync\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/docker_machine_arch.png\" style=\"float:left\" width=\"600\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "\n",
    "# create machine\n",
    "# --amazonec2-vpc-id vpc-4ee5b025 : You need to pass this if you have more than one VPC\n",
    "docker-machine create --driver amazonec2 \\\n",
    "               --amazonec2-region us-west-2 \\\n",
    "               --amazonec2-instance-type t2.micro \\\n",
    "               --amazonec2-open-port 80 \\\n",
    "               --amazonec2-vpc-id vpc-4ee5b025 docker-aws\n",
    "\n",
    "# list machines \n",
    "docker-machine ls\n",
    "\n",
    "# start the machine again\n",
    "docker-machine start docker-aws\n",
    "\n",
    "# stop the service\n",
    "docker-machine stop docker-aws\n",
    "\n",
    "# re gen certificates\n",
    "docker-machine regenerate-certs docker-aws\n",
    "\n",
    "# ssh\n",
    "docker-machine ssh docker-aws\n",
    "\n",
    "# start docker daemon in ec2 instance\n",
    "sudo service docker start\n",
    "\n",
    "# run provisioner reinstall docker daemon in case you have issues \n",
    "docker-machine provision docker-aws\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy using docker-machine\n",
    "\n",
    "It is useful to test docker applications in dev phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push image to aws ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "# old way\n",
    "$aws ecr get-login --region us-west-2 --no-include-email\n",
    "docker push XXX.dkr.ecr.us-west-2.amazonaws.com/imdb/app:$IMDB_VERSION\n",
    "\n",
    "# new way to do it\n",
    "aws ecr get-login-password  --region us-west-2  # return token \n",
    "\n",
    "# you need to do a docker login\n",
    "aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin xxx.dkr.ecr.us-west-2.amazonaws.com\n",
    "docker push xxx.dkr.ecr.us-west-2.amazonaws.com/imdb/app:$IMDB_VERSION\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug docker app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For debug and keep the container running add this to Dockerfile\n",
    "\n",
    "```yaml\n",
    "# This prevent shutdown\n",
    "ENTRYPOINT [\"tail\", \"-f\", \"/dev/null\"]\n",
    "```\n",
    "\n",
    "And run\n",
    "\n",
    "```shell\n",
    "# build the container\n",
    "docker build -t syncapp .\n",
    "\n",
    "# in my case I was using docker-compose\n",
    "docker-compose -f docker-compose-dev.yml build syncapp\n",
    "\n",
    "# run the container\n",
    "# syncapp is the image name but you can use image_id\n",
    "docker run --name syncapp -it -p 8080:8080 -v /shared:/shared XXX.dkr.ecr.us-west2.amazonaws.com/syncapp:dev /bin/bash\n",
    "\n",
    "# BETTER run with docker-compose\n",
    "docker-compose -f docker-compose-dev.yml up syncapp\n",
    "\n",
    "# ssh inside container\n",
    "docker exec -it syncapp /bin/bash\n",
    "```\n",
    "\n",
    "* check if ports is open inside container\n",
    "\n",
    "\n",
    "```shell\n",
    "# ssh into running container\n",
    "docker exec -it syncapp /bin/bash\n",
    "\n",
    "# you ight need to install netstat before \n",
    "netstat -an\n",
    "```\n",
    "\n",
    "Ex: or expected output. Port 8000 is open and listen\n",
    "\n",
    "```shell\n",
    "/imdb # netstat -an\n",
    "Active Internet connections (servers and established)\n",
    "Proto Recv-Q Send-Q Local Address           Foreign Address         State\n",
    "tcp        0      0 127.0.0.11:36787        0.0.0.0:*               LISTEN\n",
    "tcp        0      0 127.0.0.1:8000          0.0.0.0:*               LISTEN\n",
    "udp        0      0 127.0.0.11:55771        0.0.0.0:*\n",
    "Active UNIX domain sockets (servers and established)\n",
    "Proto RefCnt Flags       Type       State         I-Node Path\n",
    "unix  3      [ ]         STREAM     CONNECTED     1113208\n",
    "unix  3      [ ]         STREAM     CONNECTED     1113209\n",
    "\n",
    "\n",
    "# get swagger page for webapps\n",
    "#  Run inside and outside docker container\n",
    "\n",
    "# fastapi\n",
    "curl http://127.0.0.1:8000/docs\n",
    "\n",
    "# flaskapp\n",
    "curl https://voiceml.castingworkbook.com/swagger/index.html\n",
    "\n",
    "```\n",
    "\n",
    "* Make sure you can start the service and access outside container\n",
    "\n",
    "    * make sure you expose the port in the container \n",
    "\n",
    "docker-compose.yaml\n",
    "```yaml\n",
    "# needs this\n",
    "imdbapp:\n",
    "    container_name: imdb-container\n",
    "    # .... more code\n",
    "    environment:\n",
    "    - IMDB_VERSION=dev   # Change version when deploying new Release\n",
    "    ports:\n",
    "      - \"8000:80\"  # Need map ports\n",
    "\n",
    "````\n",
    "\n",
    "or run container with\n",
    "\n",
    "```shell\n",
    "# needs -p 8000:80. Means host 8000 -> container 80\n",
    "docker run --name imdb-app -it -p 8000:80  imdb-app:dev /bin/bash\n",
    "```\n",
    "\n",
    "app.py\n",
    "```python\n",
    "import uvicorn\n",
    "\n",
    "from fastapi import FastAPI\n",
    "\n",
    "# swagger: http://127.0.0.1:8000/docs\n",
    "# redoc: http://127.0.0.1:8000/redoc\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/items/{item_id}\")\n",
    "async def read_item(item_id: int):\n",
    "    return {\"item_id\": item_id}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=80)\n",
    "\n",
    "```\n",
    "\n",
    "Run inside the rnning container\n",
    "\n",
    "```shell\n",
    "\n",
    "# ssh into the running container\n",
    "docker exec -it imdb-container /bin/sh\n",
    "\n",
    "# on the app folder  run\n",
    "\n",
    "# 1st run as python module\n",
    "python3 app.py\n",
    "\n",
    "# test swagger page outside container in the browser private mode (is safe)\n",
    "#  http://127.0.0.1:8000/docs  \n",
    "\n",
    "# 2nd\n",
    "uvicorn app:app --host 0.0.0.0 --port 80\n",
    "\n",
    "# 3rd\n",
    "gunicorn -b 0.0.0.0:80 -w 4 -k uvicorn.workers.UvicornWorker app:app --chdir /imdb/imdb # <== folder of app.py\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "\n",
    "# Option 1: docker-machie and docker\n",
    "# remote machine\n",
    "docker-machine ssh cwb-imdb\n",
    "\n",
    "# insde the machine\n",
    "sudo docker logs imdb-container --follow\n",
    "\n",
    "#Option 2: docker-machine and docker-compose\n",
    "eval $(docker-machine env cwb-imdb)\n",
    "docker-compose logs --no-color --tail=\"all\" --follow\n",
    "\n",
    "# for especific service\n",
    "docker-compose logs --no-color --tail=\"all\"  --follow imdbapp --follow\n",
    "\n",
    "# last 200 lines\n",
    "docker-compose logs --no-color --tail=200  --follow imdbapp --follow\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kuebernetes\n",
    "\n",
    "\n",
    "refs:\n",
    "* Conf best practices: https://kubernetes.io/docs/concepts/configuration/overview/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of main terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### node\n",
    "\n",
    "* Physical or virtial machiune that host pods\n",
    "* Drain a node: \n",
    "    * safely evict all of your pods from a node before you perform maintenance on the node (e.g. kernel upgrade, hardware maintenance, etc.).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### pods: \n",
    "\n",
    "Group of containers that works together. \n",
    "\n",
    "* Each pod has it network ip and interface.\n",
    "    * Amazon and cloud services put limit in the max number of interfaces per EC2 instance (node). \n",
    "        * https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#AvailableIpPerENI\n",
    "        * https://learnk8s.io/kubernetes-node-size#:~:text=medium%20instance%2C%20the%20maximum%20number,micro%20it's%204.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"images/module_03_nodes.svg\" style=\"float:left\" width=\"500\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Deployment:\n",
    "\n",
    "refs:\n",
    "* https://blog.container-solutions.com/kubernetes-deployment-strategies\n",
    "* https://www.weave.works/blog/kubernetes-deployment-strategies\n",
    "\n",
    "A deployment is responsible for keeping a set of pods running. It is a recipe for creating copies of your application called Pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Strategies: \n",
    "    \n",
    "* recreate: terminate the old version and release the new one. This strategy will terminate all the running instances then recreate them with the newer version.\n",
    "        \n",
    "    * pros: application state entirely renewed (simple)\n",
    "    * cons: there is downtime for your application\n",
    "        \n",
    "```yaml\n",
    "spec:\n",
    "  replicas: 3\n",
    "  strategy:\n",
    "    type: Recreate\n",
    "```\n",
    "<img src=\"images/recreate-deployment-ww.png\" style=\"float:left\" width=\"500\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Rolling or ramped (**default**): release a new version on a rolling update fashion, one after the other        \n",
    "    * pros: \n",
    "        * version is slowly released across instances\n",
    "        * convenient for stateful applications that can handle rebalancing of the data\n",
    "    * cons: \n",
    "        * rollout/rollback can take time\n",
    "        * supporting multiple APIs is hard\n",
    "        * no control over traffic\n",
    "        \n",
    "```yaml\n",
    "spec:\n",
    "  replicas: 3\n",
    "  strategy:\n",
    "    type: RollingUpdate\n",
    "    rollingUpdate:\n",
    "      maxSurge: 2        # how many pods we can add at a time\n",
    "      maxUnavailable: 0  # maxUnavailable define how many pods can be unavailable\n",
    "                         # during the rolling update\n",
    "```        \n",
    "        \n",
    "<img src=\"images/rolling-deployment-ww.png\" style=\"float:left\" width=\"500\" align=\"left\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* blue/green: release a new version alongside the old version then switch traffic. \n",
    "    * pro:\n",
    "        * instant rollout/rollback\n",
    "        * avoid versioning issue, change the entire cluster state in one go\n",
    "\n",
    "    * cons: \n",
    "        * requires double the resources\n",
    "        * proper test of the entire platform should be done before releasing to production\n",
    "        * handling stateful applications can be hard\n",
    "\n",
    "\n",
    "Users only have access to the green; whereas, the blue is available to your QA team for test automation on a separate service or via direct port-forwarding.\n",
    "\n",
    "<img src=\"images/blue-green-deployment-ww.png\" style=\"float:left\" width=\"500\" align=\"left\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* canary: release a new version to a subset of users, then proceed to a full rollout\n",
    "           * pro:\n",
    "                * version released for a subset of users\n",
    "                * convenient for error rate and performance monitoring\n",
    "                * fast rollback\n",
    "           * cons: \n",
    "                * slow rollout\n",
    "                * fine tuned traffic distribution can be expensive (99% A/ 1%B = 99 pod A, 1 pod B)\n",
    "                \n",
    "\n",
    "<img src=\"images/canary-deployment-ww.png\" style=\"float:left\" width=\"500\" align=\"left\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* a/b testing: release a new version to a subset of users in a precise way (HTTP headers, cookie, weight, etc.). A/B testing is really a technique for making business decisions based on statistics but we will briefly describe the process.\n",
    "\n",
    "\n",
    "<img src=\"images/flagger-abtest-steps.png\" style=\"float:left\" width=\"500\" align=\"left\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### services: \n",
    "\n",
    "A servce is responsible for enabling network access to a set of pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types:\n",
    "* ClusterIP: **default**. You can only reach the node inside the cluster network\n",
    "* NodePort: From outside the cluster, you can contact the NodePort service by using `<NodeIP>:<NodePort>`.\n",
    "* LoadBalancer: Exposes the service externally using the load balancer of your cloud provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/kubernetes_bigpicture.png\" style=\"float:left\" width=\"600\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### eksctl commands\n",
    "\n",
    "refs:\n",
    "* https://thanhtungvo.medium.com/eksctl-a-great-cli-tool-for-amazon-eks-36636e268d90\n",
    "* https://eksctl.io/introduction/\n",
    "\n",
    "\n",
    "<p style=\"color:red\">eksctl can RESTART EC2 INSTANCES AUTOMATIC. SO ALWAYS DELETE THE CLUSTER TO MAKE SURE NO INSTANCE WILL BE RUNNING ON AWS.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Create and get info about the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "```bash\n",
    "\n",
    "# create cluster\n",
    "eksctl create cluster --name=cluster-5 --nodes-min=1 --nodes-max=2\n",
    "\n",
    "# get a list of clusters\n",
    "eksctl get clusters\n",
    "\n",
    "# delete cluster\n",
    "eksctl delete cluster --name=<name> [--region=<region>]\n",
    "\n",
    "\n",
    "# get nodegroups. Its way to define groups of nodes and run commands in all of this nodes. One scenario would be update all EC2 instances\n",
    "eksctl get nodegroup --cluster=cluster_name\n",
    "\n",
    "# For ekstcl it is not automatic delete load balancer if there are any services in the clusters so you need to delete service by manual.\n",
    "kubectl get svc --all-namespaces\n",
    "kubectl delete svc service-name --namespace=[namesapce]\n",
    "\n",
    "# Allow ssh access to a node\n",
    "eksctl create cluster --ssh-access --ssh-public-key=my_eks_node_id.pub\n",
    "# sshould see a msg:\n",
    "# importing SSH public key \"/home/<USER_NAME>/.ssh/id_rsa.pub\" as \"eksctl-xxx-nodegroup-ng-axxx-xx:xx:xx:xx:xx:xx:xx\"\n",
    "\n",
    "# now you can ssh with:\n",
    "ssh -i /home/<USER_NAME>/.ssh/id_rsa.pub ec2-user@ec2-xx-xx-xx-xx\n",
    "\n",
    "# or to use pre-existing EC2 key pair in us-east-1 region, \n",
    "eksctl create cluster --ssh-access --ssh-public-key=my_kubernetes_key --region=us-east-1\n",
    "\n",
    "# in the case you generate kubectl config file. USEFUL for CI server migration\n",
    "eksctl utils write-kubeconfig --cluster=<name> [--kubeconfig=<out_path>][--set-kubeconfig-context=<bool>]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Get status and info of the cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```sh\n",
    "\n",
    "# Gte nodes status\n",
    "eksctl get nodegroups --cluster=cwb-agoraio-recording-cluster\n",
    "\n",
    "# get services running in the cluster\n",
    "kubectl get svc --all-namespaces\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Add or delete nodes in a cluster\n",
    "\n",
    "https://eksctl.io/usage/managing-nodegroups/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "```sh\n",
    "\n",
    "# get nodegroups. Its way to define groups of nodes and run commands in all of this nodes. One scenario would be update all EC2 instances\n",
    "eksctl get nodegroup --cluster=<clusterName>\n",
    "\n",
    "#For example, to scale nodegroup ng-a345f4e1 in cluster-1 to 5 nodes, run:\n",
    "# eksctl scale nodegroup --cluster=<clusterName> --nodes=<desiredCount> --name=<nodegroupName> [ --nodes-min=<minSize> ] [ --nodes-max=<maxSize> ]\n",
    "eksctl scale nodegroup --cluster=cwb-agoraio-recording-cluster --nodes=3 cwb-agora-job-manager\n",
    "\n",
    "\n",
    "# delete\n",
    "eksctl delete nodegroup --cluster=<clusterName> --name=<nodegroupName>\n",
    "\n",
    "# drain: safely evict all of your pods from a node before you perform maintenance on the node (e.g. kernel upgrade, hardware maintenance, etc.).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kubectl commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get info about clusters, context and config files \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "\n",
    "# summary info\n",
    "kubectl config get-contexts\n",
    "\n",
    "# see conf file \n",
    "kubectl config view\n",
    "\n",
    "# Get cluster info\n",
    "kubectl cluster-info\n",
    "\n",
    "# Get clusters status\n",
    "kubectl get cs\n",
    "\n",
    "# all commands can be execute by specifying the kubeconfig file\n",
    "kubectl --kubeconfig=\"config\" config view\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```sh\n",
    "\n",
    "# get info about nodes\n",
    "kubectl describe node/ip-XX-XX-XX-X23.us-west-2.compute.internal\n",
    "```\n",
    "Outputs\n",
    "* Hinst:\n",
    "    * CPU , memory and network usage if it is enough or not\n",
    "* Stats\n",
    "    * CPU and memory usage per pods in the node\n",
    "\n",
    "Ex: output.\n",
    "Pay attention. The report give youo statisics about the nodes and hints like you have enough cpu or memory in thw node\n",
    "\n",
    "\n",
    "* **Drain a node for matenance**\n",
    "\n",
    "```sh\n",
    "kubectl drain <node name>\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get info of the services and pods :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# get info all services, replicas and deploymenst\n",
    "kubectl get all\n",
    "\n",
    "# get a list of all services running in the cluser\n",
    "kubectl get svc\n",
    "\n",
    "# describe service\n",
    "kubectl describe services my-flask-service\n",
    "\n",
    "# get info about pods\n",
    "kubectl get pods  -o wide --show-labels\n",
    "\n",
    "# get info about clusters nodes (nodes is different form pods)\n",
    "kubectl get nodes\n",
    "\n",
    "\n",
    "# get all pods running in a node. EC2 ins\n",
    "kubectl get pods --all-namespaces -o wide --field-selector spec.nodeName=ip-192-168-X-XXX.us-west-2.compute.internal\n",
    "\n",
    "```\n",
    "\n",
    "**Accessing PODS and Nodes:**\n",
    "\n",
    "```sh\n",
    "# \"ssh\" into a pod: kubectl exec -it <POD-NAME> /bin/sh\n",
    "kubectl get pods  # discover pod names\n",
    "kubectl exec -it my-flask-844778465d-q4vwr /bin/sh # run ps, top to inspect the pod env\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Deployments:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "kubectl apply -f deployment.yaml\n",
    "\n",
    "kubectl get deployments [deployment-name]\n",
    "\n",
    "# get rollout info\n",
    "kubectl rollout status deployment/cwb-agoraio-flask\n",
    "\n",
    "# see all the replicas \n",
    "kubectl get rs -o wide --show-labels \n",
    "\n",
    "# undo deployment to previous stable deployed version\n",
    "kubectl rollout undo deployment cwb-agoraio-flask\n",
    "\n",
    "# View the rollout history of a deployment\n",
    "kubectl rollout history deployment/cwb-agoraio-flask\n",
    "\n",
    "```\n",
    "\n",
    "Output:\n",
    "* NAME lists the names of the Deployments in the namespace.\n",
    "* READY displays how many replicas of the application are available to your users. It follows the pattern ready/desired.\n",
    "* UP-TO-DATE displays the number of replicas that have been updated to achieve the desired state.\n",
    "* AVAILABLE displays how many replicas of the application are available to your users.\n",
    "* AGE displays the amount of time that the application has been running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Logs and debugging:**\n",
    "\n",
    "https://kubernetes.io/docs/reference/kubectl/cheatsheet/\n",
    "\n",
    "* **Get logs for a pod**\n",
    "\n",
    "```sh\n",
    "# get logs\n",
    "kubectl describe replicasets  # get pods names\n",
    "kubectl logs cwb-agoraio-flask-d6976987-vx6gt  # get los from one pod\n",
    "\n",
    "# get logs for all pods\n",
    "## 1st Discver all labels assigned to a pod with\n",
    "kubectl describe pods cwb-agoraio-flask-7f4977d46-9tjnw\n",
    "```\n",
    "\n",
    "\n",
    "**Output example**\n",
    "```yaml\n",
    "Start Time:   Fri, 12 Mar 2021 13:08:26 -0800\n",
    "Labels:       app=cwb-agoraio-flask\n",
    "              pod-template-hash=7f4977d46\n",
    "Annotations:  kubernetes.io/psp: eks.privileged\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```sh\n",
    "\n",
    "# Get logs for all pods \n",
    "# for stream logs use the option -f\n",
    "kubectl logs -f -l app=cwb-agoraio-flask --all-containers\n",
    "\n",
    "# Display only the most recent 20 lines of output in pod nginx\n",
    "kubectl logs --tail=20 nginx\n",
    "\n",
    "# Show all logs from pod nginx written in the last hour\n",
    "kubectl logs --since=1h nginx  ## <=== This is cool\n",
    "\n",
    "# Only return logs after a specific date (RFC3339)\n",
    "kubectl logs --since-time=\"2021-02-01T07:20:50.52Z\"  -l app=cwb-agoraio-flask --all-containers\n",
    "\n",
    "```\n",
    "\n",
    "* **Get all events log in a cluster**\n",
    "\n",
    "```sh\n",
    "\n",
    "# get event show history and events logs of the kubectl client\n",
    "kubectl get events\n",
    "\n",
    "# get rollout info\n",
    "kubectl rollout status deployment/cwb-agoraio-flask\n",
    "\n",
    "```\n",
    "\n",
    "* Discover why pods are pending\n",
    "\n",
    "```sh\n",
    "# get status for all pods; PENDING, RUNNING, ImagePullBackOff (image missing), CrashLoopBackOff\n",
    "kubectl get  pods\n",
    "\n",
    "```\n",
    "\n",
    "Common erros status returned by kubectl get pods:\n",
    "* ImagePullBackOff: forgot to push the image\n",
    "* CrashLoopBackOff: pods is crashing in the start. probably a code typo, missing parentehsis\n",
    "\n",
    "\n",
    "```sh \n",
    "\n",
    "# Get a message of the status of specifc pods \n",
    "kubectl describe pod cwb-agoraio-flask-9bdc9bc4-gdfww   # pending\n",
    "kubectl describe pod cwb-agoraio-flask-9bdc9bc4-bp8gs   # running also gives info which nodes is running\n",
    "\n",
    "\n",
    "# Get all pods running in a node\n",
    "kubectl describe node/ip-192-xx-xx-xx8.us-west-2.compute.internal\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kubernetes dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Move/configure kubectl to work on AWS\n",
    "\n",
    "\n",
    "* Scenario\n",
    "    * you are moving jenkins server to another machine \n",
    "    * you have a new dev machine and you need to set kubectl\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```sh\n",
    "# discovery clusters names\n",
    "eksctl get clusters\n",
    "\n",
    "# creat new configuration file\n",
    "aws eks --region us-west-2 update-kubeconfig --name cwb-agoraio-recording-cluster\n",
    "\n",
    "# test\n",
    "kubectl get svc --all-namespaces\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### How to upscale (horizontal scale) ec2 instance of the the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "```sh\n",
    "# list all cluster to get the name of the cluster\n",
    "eksctl get cluster\n",
    "\n",
    "# inspectig ec2 instance type of the cluster\n",
    "eksctl get nodegroups --cluster=cwb-agoraio-recording-cluster\n",
    "\n",
    "# cretae a new nodegrpup with the ec2 instance type you want to create\n",
    "eksctl create nodegroup \\\n",
    "       --cluster  cwb-agoraio-recording-cluster\\\n",
    "       --version 1.18 \\\n",
    "       --name cwb-agoraio-job-manager-2 \\\n",
    "       --node-type t2.small \\\n",
    "       --nodes 3 \\\n",
    "       --nodes-min 2 \\\n",
    "       --nodes-max 5 \\\n",
    "       --node-ami auto\n",
    "\n",
    "# check all new nodes are up\n",
    "kubectl get nodes\n",
    "\n",
    "# inspencting the node and the ec2 instance type\n",
    "eksctl get nodegroups --cluster=cwb-agoraio-recording-cluster \n",
    "\n",
    "# delete all nodes of the old nodesgroup\n",
    "eksctl delete nodegroup --cluster cwb-agoraio-recording-cluster --name cwb-agora-job-manager\n",
    "\n",
    "# inspencting the node and the ec2 instance type\n",
    "eksctl get nodegroups --cluster=cwb-agoraio-recording-cluster \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Example simple flask app and Load Balancer kubernetes service\n",
    "\n",
    "\n",
    "> * You need AWS account ready\n",
    "> * You need AWS CLI already ready with credentials set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Flask App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Create virtual cluster on AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The commmands takes about 5 to 10 minutes on AWS i order to get the cluster ready.\n",
    "\n",
    "```bash\n",
    "# Create a cluster with 2 nodes\n",
    "# Needs permission to create IAM role for the cluster\n",
    "eksctl create cluster \\\n",
    "       --name test-cluster \\\n",
    "       --region us-west-2 \\\n",
    "       --nodegroup-name linux-nodes \\\n",
    "       --node-type t2.micro \\\n",
    "       --nodes 2 # 2 work nodes\n",
    "\n",
    "# Or you can save the conf in yaml file and run\n",
    "eksctl create cluster -f cluster.yaml\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using yaml file: eks.yaml\n",
    "\n",
    "```yaml\n",
    "apiVersion: eksctl.io/v1alpha5\n",
    "kind: ClusterConfig\n",
    "metadata:\n",
    "  name: my-cluster\n",
    "  region: ap-southeast-1\n",
    "managedNodeGroups:\n",
    "  - name: job-manager\n",
    "    instanceType: t3a.micro\n",
    "    desiredCapacity: 2\n",
    "    minSize: 2\n",
    "    maxSize: 10\n",
    "    tags:\n",
    "      'Project': 'KubernetesNoob'\n",
    "```\n",
    "\n",
    "```bash\n",
    "\n",
    "# Or you can save the conf in yaml file and run\n",
    "eksctl create cluster -f cluster.yaml\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can inspect the cluster\n",
    "\n",
    "\n",
    "```bash\n",
    "# where kube save info about the cluster\n",
    "cat ~/.kube/config\n",
    "\n",
    "# you can run kubctl commands now\n",
    "kubectl get nodes\n",
    "\n",
    "# get namespace.\n",
    "# kubectl support many virtual clsuter under the same physical cluster\n",
    "kubectl get ns  \n",
    "kubectl get pod ## It is empty now\n",
    "\n",
    "\n",
    "# in case you want to delete\n",
    "# Cleanup malformed clusters\n",
    "eksctl delete cluster --region=us-west-2 --name=test-cluster\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Push a dockerize app image to ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. **Build the dockerized app**\n",
    "\n",
    "```bash\n",
    "docker build -f Dockerfile -t my-flask-image:latest\n",
    "\n",
    "# see the image\n",
    "docker images\n",
    "\n",
    "# run the the dockerized app\n",
    "docker run -p 5001:5000 my-flask-image\n",
    "\n",
    "# In the case you want to run without docker\n",
    "# http://localhost:5000 \n",
    "python app/main.py\n",
    "```\n",
    "\n",
    "1. Create a new repo on ECR\n",
    "    1. pickup a name: my-flask\n",
    "    1. Look view push commands for help\n",
    "\n",
    "\n",
    "```bash\n",
    "export AWS_ACCOUNT_ID=\"44XXXXXXXX69\"\n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "# tag\n",
    "docker tag my-flask-image:latest ${AWS_ACCOUNT_ID}.dkr.ecr.us-west-2.amazonaws.com/my-flask:latest\n",
    "\n",
    "# get ECR authentication for docker client\n",
    "aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin ${AWS_ACCOUNT_ID}.dkr.ecr.us-west-2.amazonaws.com\n",
    "\n",
    "# push to ECR\n",
    "docker push ${AWS_ACCOUNT_ID}.dkr.ecr.us-west-2.amazonaws.com/my-flask:latest\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Create kuberbetes Load Balancer service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "1. Create a Load Balnace service: Create the file: deployment.yaml (It has service and deployment kubectl configuration)\n",
    "    \n",
    "   * Expose the cluster PORT 8080 for external access\n",
    "   * Instanciate 2 pods in the eks cluster. replicas of the dockerized flask app \n",
    " \n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service   # <= service config\n",
    "metadata:\n",
    "  name: my-flask-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: my-flask\n",
    "  ports:\n",
    "  - protocol: \"TCP\"\n",
    "    port: 6000    # <= service expose port in the cluster\n",
    "    targetPort: 5000 # <== Target port. It port 6000 will be redirect to 5000\n",
    "  type: LoadBalancer  # <= service type\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment  # <= service config\n",
    "metadata:\n",
    "  name: my-flask\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: my-flask\n",
    "  replicas: 2  # <= We are creating 2 replicas of flask app\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: my-flask\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: my-flask\n",
    "        image: ${AWS_ACCOUNT_ID}.dkr.ecr.us-west-2.amazonaws.com/my-flask:latest   # <= ECR URI\n",
    "        ports:\n",
    "        - containerPort: 5000   # <= opened port in the containers \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Run the commands\n",
    "\n",
    "```bash\n",
    "\n",
    "kubectl apply -f deployment.yaml\n",
    "\n",
    "# get info about the deployment \n",
    "kubectl get deployments my-flask\n",
    "\n",
    "kubectl describe deployments my-flask\n",
    "\n",
    "kubectl get replicasets\n",
    "kubectl describe replicasets\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Accessing the running container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**From local you can use kubectl proxy**\n",
    "\n",
    "\n",
    "```bash\n",
    "kubectl proxy --port 8080\n",
    "\n",
    "# Get the API versions:\n",
    "curl http://localhost:8080/api/\n",
    "\n",
    "# Get list of pods\n",
    "curl http://localhost:8080/api/v1/namespaces/default/pods\n",
    "\n",
    "```\n",
    "\n",
    "http://localhost:8080/api/v1/namespaces/default/services/my-flask-service/proxy/uname\n",
    "\n",
    "\n",
    "> Every time you refresh you can see the Load Balancer calling different pod every time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**From external**\n",
    "\n",
    "1. Change the service expose port from 6000 to 8080. The port 6000 should NOT be opened on AWS.\n",
    "1. Delete the service and recreate it again\n",
    "\n",
    "\n",
    "```bash\n",
    "# delete the service\n",
    "kubectl delete svc  my-flask-service\n",
    "\n",
    "# recreate again the service\n",
    "kubectl apply -f deployment.yaml\n",
    "\n",
    "# Get info about the service\n",
    "kubectl describe services my-flask-service\n",
    "\n",
    "```\n",
    "Expect output of kubectl describe services \n",
    "\n",
    "\n",
    "```yaml\n",
    "Name:                     my-flask-service\n",
    "Namespace:                default\n",
    "Labels:                   <none>\n",
    "Annotations:              <none>\n",
    "Selector:                 app=my-flask\n",
    "Type:                     LoadBalancer\n",
    "IP Families:              <none>\n",
    "IP:                       <CLUSTER IP>\n",
    "IPs:                      <none>\n",
    "LoadBalancer Ingress:     <EXTERNAL IP or DNS>\n",
    "Port:                     <unset>  8080/TCP\n",
    "TargetPort:               5000/TCP\n",
    "NodePort:                 <unset>  31228/TCP\n",
    "Endpoints:                192.X.X.15X:5000,192.X.X.4X:5000\n",
    "Session Affinity:         None\n",
    "External Traffic Policy:  Cluster\n",
    "Events:\n",
    "  Type    Reason                Age   From                Message\n",
    "  ----    ------                ----  ----                -------\n",
    "  Normal  EnsuringLoadBalancer  42s   service-controller  Ensuring load balancer\n",
    "  Normal  EnsuredLoadBalancer   40s   service-controller  Ensured load balancer\n",
    "\n",
    "```\n",
    "\n",
    "Notes:\n",
    "\n",
    "* ```<EXTERNAL IP or DNS>``` : You should use this in the browser to access the swagger API of the app\n",
    "* Endpoints: Are the IP address of each POD replica in the cluster under this service\n",
    "\n",
    "http://```<EXTERNAL IP or DNS>```:8080/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Jenkins "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* CI Pipeline with docker and jenkins\n",
    "-------\n",
    "<img src=\"images/high_level_flow_docker_n_jenkins.png\" style=\"float:left\" width=\"600\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### terms and tips to mange jenkins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```sh\n",
    "\n",
    "# initial jenkins pwd to unlock jenkins. We need to be log in as jenkins user\n",
    "cat ~/secrets/initialAdminPassword\n",
    "\n",
    "\n",
    "# jenkins jobs (jekins pipeline) location\n",
    "ls ~/job\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.367px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
